{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, seq_len):\n",
    "        super(LSTM_Autoencoder, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, input_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device) \n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        encoded, (hn, cn) = self.encoder(x, (h0, c0))\n",
    "        decoded, _ = self.decoder(encoded, (hn, cn))\n",
    "        decoded = self.output_layer(decoded)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data_recs, data_columns,):\n",
    "    for idx, data_rec in enumerate(data_recs):\n",
    "        print(f\"Processing record {idx + 1}...\")\n",
    "\n",
    "        data_rec = pd.DataFrame([data_rec], columns=data_columns)\n",
    "\n",
    "        missing_values = data_rec.isnull().sum()\n",
    "        if len(missing_values[missing_values > 0]):\n",
    "            print(missing_values[missing_values > 0])\n",
    "            data_rec.fillna(0, inplace=True)\n",
    "        else:\n",
    "            print('There are no missing values in the record')\n",
    "\n",
    "        for i in range(1, 21):\n",
    "            if data_rec.iloc[0, i] not in [0, 1]:\n",
    "                print(f\"Invalid value in column {i}. Assigned value: 0\")\n",
    "                data_rec.iloc[0, i] = 0\n",
    "\n",
    "        for i in range(21, 23):\n",
    "            if (data_rec.iloc[0, i] < 1) or (data_rec.iloc[0, i] > 27):\n",
    "                print(f\"Invalid value in column {i}. Assigned value: 1\")\n",
    "                data_rec.iloc[0, i] = 1\n",
    "\n",
    "        print('Checked for invalid values and imputed the same')\n",
    "        print('Using the LSTM Encoder, Standard scaler and Reconstruction Errors to check if the record is an anomaly')\n",
    "        \n",
    "        if 'Unnamed: 0' in data_rec.columns:\n",
    "            data_rec = data_rec.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "        input_size = 25  \n",
    "        hidden_size = 256\n",
    "        seq_len = 1\n",
    "\n",
    "        model_path = \"./House B files/lstm_autoencoder_hb.pth\"\n",
    "        scaler_path = \"./House B files/standardscaler_hb.joblib\"\n",
    "        reconstruction_error_path = \"./House B files/reconstruction_errors_hb.npy\"\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "        model = LSTM_Autoencoder(input_size=input_size, hidden_size=hidden_size, seq_len=seq_len)\n",
    "\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        if any(key.startswith(\"module.\") for key in state_dict.keys()):\n",
    "            state_dict = {key[len(\"module.\"):]: value for key, value in state_dict.items()}\n",
    "\n",
    "        try:\n",
    "            model.load_state_dict(state_dict)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Ensure the model architecture matches the saved state_dict structure.\")\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        reconstruction_errors = np.load(reconstruction_error_path)\n",
    "        threshold = np.percentile(reconstruction_errors, 95)\n",
    "\n",
    "        sc = load(scaler_path)\n",
    "        new_data = sc.transform(data_rec)\n",
    "        new_data_tensor = torch.tensor(new_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            new_data_reconstructed = model(new_data_tensor)\n",
    "            reconstruction_error = torch.mean((new_data_tensor - new_data_reconstructed) ** 2).item()\n",
    "\n",
    "        print(reconstruction_error,threshold)\n",
    "        is_anomaly = reconstruction_error > threshold\n",
    "        if is_anomaly:\n",
    "            print(f\"Record {idx + 1}: Current Record is an anomaly\\n\")\n",
    "        else:\n",
    "            print(f\"Record {idx + 1}: Current Record is not an anomaly\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record 1...\n",
      "No missing values in the record\n",
      "0.15277859568595886 0.00014203230966813862\n",
      "Record 1: Current Record is an anomaly\n",
      "\n",
      "Processing record 2...\n",
      "No missing values in the record\n",
      "0.001681121182627976 0.00014203230966813862\n",
      "Record 2: Current Record is an anomaly\n",
      "\n",
      "Processing record 3...\n",
      "No missing values in the record\n",
      "0.4561891257762909 0.00014203230966813862\n",
      "Record 3: Current Record is an anomaly\n",
      "\n",
      "Processing record 4...\n",
      "No missing values in the record\n",
      "0.0005036143702454865 0.00014203230966813862\n",
      "Record 4: Current Record is an anomaly\n",
      "\n",
      "Processing record 5...\n",
      "No missing values in the record\n",
      "3.8098819459264632e-06 0.00014203230966813862\n",
      "Record 5: Current Record is not an anomaly\n",
      "\n",
      "Processing record 6...\n",
      "No missing values in the record\n",
      "0.00010944623500108719 0.00014203230966813862\n",
      "Record 6: Current Record is not an anomaly\n",
      "\n",
      "Processing record 7...\n",
      "No missing values in the record\n",
      "0.0035113764461129904 0.00014203230966813862\n",
      "Record 7: Current Record is an anomaly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# houseb = pd.read_csv(\"../Aras/house_b_combined_dataset.csv\")\n",
    "\n",
    "data_columns = ['Unnamed: 0', 'contact_kitchen_cupboard_1',\n",
    "       'contact_kitchen_cupboard_2', 'contact_house_door',\n",
    "       'contact_wardrobe_door_1', 'contact_wardrobe_door_2',\n",
    "       'contact_shower_door', 'distance_tap', 'force_chair_1', 'force_chair_2',\n",
    "       'force_chair_3', 'photocell_fridge', 'photocell_kitchen_drawer',\n",
    "       'pressure_mat_couch_1', 'pressure_mat_couch_2', 'pressure_mat_bed_1',\n",
    "       'pressure_mat_bed_2', 'pressure_mat_armchair', 'sonar_bathroom_door',\n",
    "       'sonar_kitchen', 'sonar_closet', 'Resident1', 'Resident2', 'Hour',\n",
    "       'Week', 'Day Of Week']\n",
    "\n",
    "data_recs = [[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,12,17,0,0,0], # Wrong day and week passed\n",
    "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,2,14,1,1], #Both going out but sensor is active \n",
    "             [1898791,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,2,23,4.0,1.0], #Conatct sensor at Kitchen cupboard is on but one resident is studying and other is going out\n",
    "             [1210121,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,16,0,3.0,1.0], #both are sleeping but none of the sensor are active\n",
    "             [1210121,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,11,11,4,3.0,1.0], #both are sleeping bed sensors are active\n",
    "             [2278363,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,1,8,4.0,6.0], #Random record from dataset\n",
    "             [2278363,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,13,1,8,4.0,6.0], #Random record changed a bit\n",
    "             ] \n",
    "\n",
    "pipeline(data_recs, data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
