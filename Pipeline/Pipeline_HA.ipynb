{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, seq_len):\n",
    "        super(LSTM_Autoencoder, self).__init__()\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, input_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device) \n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        encoded, (hn, cn) = self.encoder(x, (h0, c0))\n",
    "        decoded, _ = self.decoder(encoded, (hn, cn))\n",
    "        decoded = self.output_layer(decoded)\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data_recs, data_columns,):\n",
    "    for idx, data_rec in enumerate(data_recs):\n",
    "        print(f\"Processing record {idx + 1}...\")\n",
    "\n",
    "        data_rec = pd.DataFrame([data_rec], columns=data_columns)\n",
    "\n",
    "        missing_values = data_rec.isnull().sum()\n",
    "        if len(missing_values[missing_values > 0]):\n",
    "            print(missing_values[missing_values > 0])\n",
    "            data_rec.fillna(0, inplace=True)\n",
    "        else:\n",
    "            print('No missing values in the record')\n",
    "\n",
    "        for i in range(1, 21):\n",
    "            if data_rec.iloc[0, i] not in [0, 1]:\n",
    "                print(f\"Invalid value in column {i}. Assigned value: 0\")\n",
    "                data_rec.iloc[0, i] = 0\n",
    "\n",
    "        for i in range(21, 23):\n",
    "            if (data_rec.iloc[0, i] < 1) or (data_rec.iloc[0, i] > 27):\n",
    "                print(f\"Invalid value in column {i}. Assigned value: 1\")\n",
    "                data_rec.iloc[0, i] = 1\n",
    "\n",
    "\n",
    "        if 'Unnamed: 0' in data_rec.columns:\n",
    "            data_rec = data_rec.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "        input_size = 25  \n",
    "        hidden_size = 256\n",
    "        seq_len = 1\n",
    "\n",
    "        model_path = \"./House A files/lstm_autoencoder_ha.pth\"\n",
    "        scaler_path = \"./House A files/standardscaler_ha.joblib\"\n",
    "        reconstruction_error_path = \"./House A files/reconstruction_errors_ha.npy\"\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "        model = LSTM_Autoencoder(input_size=input_size, hidden_size=hidden_size, seq_len=seq_len)\n",
    "\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        if any(key.startswith(\"module.\") for key in state_dict.keys()):\n",
    "            state_dict = {key[len(\"module.\"):]: value for key, value in state_dict.items()}\n",
    "\n",
    "        try:\n",
    "            model.load_state_dict(state_dict)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Ensure the model architecture matches the saved state_dict structure.\")\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        reconstruction_errors = np.load(reconstruction_error_path)\n",
    "        threshold = np.percentile(reconstruction_errors, 95)\n",
    "\n",
    "        sc = load(scaler_path)\n",
    "        new_data = sc.transform(data_rec)\n",
    "        new_data_tensor = torch.tensor(new_data, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            new_data_reconstructed = model(new_data_tensor)\n",
    "            reconstruction_error = torch.mean((new_data_tensor - new_data_reconstructed) ** 2).item()\n",
    "\n",
    "        print(reconstruction_error,threshold)\n",
    "        is_anomaly = reconstruction_error > threshold\n",
    "        if is_anomaly:\n",
    "            print(f\"Record {idx + 1}: Current Record is an anomaly\\n\")\n",
    "        else:\n",
    "            print(f\"Record {idx + 1}: Current Record is not an anomaly\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record 1...\n",
      "No missing values in the record\n",
      "0.0003835099923890084 0.00016964174574241042\n",
      "Record 1: Current Record is an anomaly\n",
      "\n",
      "Processing record 2...\n",
      "No missing values in the record\n",
      "0.00014498601376544684 0.00016964174574241042\n",
      "Record 2: Current Record is not an anomaly\n",
      "\n",
      "Processing record 3...\n",
      "No missing values in the record\n",
      "0.0005591337103396654 0.00016964174574241042\n",
      "Record 3: Current Record is an anomaly\n",
      "\n",
      "Processing record 4...\n",
      "No missing values in the record\n",
      "0.0025089625269174576 0.00016964174574241042\n",
      "Record 4: Current Record is an anomaly\n",
      "\n",
      "Processing record 5...\n",
      "No missing values in the record\n",
      "0.0011899829842150211 0.00016964174574241042\n",
      "Record 5: Current Record is an anomaly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# houseA = pd.read_csv(\"../Aras/house_a_combined_dataset.csv\")\n",
    "\n",
    "data_columns = [\"Unnamed: 0\",'photocell_wardrobe', 'photocell_couch', 'ir_tv_receiver',\n",
    "       'force_couch_1', 'force_couch_2', 'distance_chair_1',\n",
    "       'distance_chair_2', 'photocell_fridge', 'photocell_kitchen_drawer',\n",
    "       'photocell_wardrobe_2', 'photocell_bathroom_cabinet',\n",
    "       'contact_house_door', 'contact_bathroom_door', 'contact_shower_door',\n",
    "       'sonar_hall', 'sonar_kitchen', 'distance_tap', 'distance_water_closet',\n",
    "       'temperature_kitchen', 'force_bed', 'Resident1', 'Resident2', 'Hour',\n",
    "       'Week', 'Day Of Week']\n",
    "\n",
    "data_recs = [[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,12,17,0,0,0], # Wrong day and week passed\n",
    "             [0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,12,17,0,1,1], # Possible day and week passed\n",
    "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,2,14,1,1], #Both resident are out and some senor is active\n",
    "             [0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,11,11,14,1,1], #Both resident sleeping and house door is open\n",
    "             [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,12,11,14,1,1]] #Residents are watching TV or sleeping but kitchen temperature sensor is active \n",
    "\n",
    "pipeline(data_recs, data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
