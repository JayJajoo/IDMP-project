{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9877061,"sourceType":"datasetVersion","datasetId":6063935}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nfrom torch.cuda.amp import autocast, GradScaler\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:06.181532Z","iopub.execute_input":"2024-11-13T04:36:06.182288Z","iopub.status.idle":"2024-11-13T04:36:06.187651Z","shell.execute_reply.started":"2024-11-13T04:36:06.182247Z","shell.execute_reply":"2024-11-13T04:36:06.186694Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/house-a/house_a_combined_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:06.192811Z","iopub.execute_input":"2024-11-13T04:36:06.193161Z","iopub.status.idle":"2024-11-13T04:36:10.139829Z","shell.execute_reply.started":"2024-11-13T04:36:06.193124Z","shell.execute_reply":"2024-11-13T04:36:10.138842Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Assuming 'df' is the DataFrame that contains your data\n# Preprocessing: Drop the Hour, Resident columns for simplicity\ndata = df.drop(columns=['Hour', 'Resident1', 'Resident2']).values  # Remove non-sensor data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:10.142200Z","iopub.execute_input":"2024-11-13T04:36:10.142925Z","iopub.status.idle":"2024-11-13T04:36:10.285746Z","shell.execute_reply.started":"2024-11-13T04:36:10.142876Z","shell.execute_reply":"2024-11-13T04:36:10.284900Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Normalize or standardize data if needed\nscaler = StandardScaler()\ndata = scaler.fit_transform(data)  # Normalize sensor data (optional)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:10.287126Z","iopub.execute_input":"2024-11-13T04:36:10.287577Z","iopub.status.idle":"2024-11-13T04:36:11.060396Z","shell.execute_reply.started":"2024-11-13T04:36:10.287526Z","shell.execute_reply":"2024-11-13T04:36:11.059167Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Convert data to tensor\ndata_tensor = torch.tensor(data, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.061945Z","iopub.execute_input":"2024-11-13T04:36:11.062312Z","iopub.status.idle":"2024-11-13T04:36:11.150896Z","shell.execute_reply.started":"2024-11-13T04:36:11.062277Z","shell.execute_reply":"2024-11-13T04:36:11.149914Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Create Dataset and DataLoader for batch processing\nbatch_size = 2**17  # Adjust based on GPU memory availability\ndataset = TensorDataset(data_tensor)\ndata_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.153560Z","iopub.execute_input":"2024-11-13T04:36:11.153906Z","iopub.status.idle":"2024-11-13T04:36:11.159139Z","shell.execute_reply.started":"2024-11-13T04:36:11.153849Z","shell.execute_reply":"2024-11-13T04:36:11.158219Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass LSTM_Autoencoder(nn.Module):\n    def __init__(self, input_size, hidden_size, seq_len):\n        super(LSTM_Autoencoder, self).__init__()\n        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n        self.output_layer = nn.Linear(hidden_size, input_size)\n        self.hidden_size = hidden_size\n        self.seq_len = seq_len\n\n    def forward(self, x):\n        # Initialize hidden and cell states for encoder\n        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # batch_size, hidden_size\n        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # batch_size, hidden_size\n        \n        # Pass through encoder\n        encoded, (hn, cn) = self.encoder(x, (h0, c0))\n        \n        # Pass through decoder\n        decoded, _ = self.decoder(encoded, (hn, cn))\n        \n        # Map decoded output back to input size\n        decoded = self.output_layer(decoded)\n        \n        return decoded\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.160281Z","iopub.execute_input":"2024-11-13T04:36:11.160589Z","iopub.status.idle":"2024-11-13T04:36:11.169604Z","shell.execute_reply.started":"2024-11-13T04:36:11.160559Z","shell.execute_reply":"2024-11-13T04:36:11.168755Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Model Hyperparameters\ninput_size = data.shape[1]  # Number of sensor features\nhidden_size = 64  # You can adjust this based on your model's complexity\nseq_len = 1  # We are feeding one time step at a time (if you want multi-step sequence, change this)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.170635Z","iopub.execute_input":"2024-11-13T04:36:11.172976Z","iopub.status.idle":"2024-11-13T04:36:11.180142Z","shell.execute_reply.started":"2024-11-13T04:36:11.172942Z","shell.execute_reply":"2024-11-13T04:36:11.179254Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Initialize the model and move it to GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = LSTM_Autoencoder(input_size=input_size, hidden_size=hidden_size, seq_len=seq_len).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.181335Z","iopub.execute_input":"2024-11-13T04:36:11.181813Z","iopub.status.idle":"2024-11-13T04:36:11.191563Z","shell.execute_reply.started":"2024-11-13T04:36:11.181781Z","shell.execute_reply":"2024-11-13T04:36:11.190721Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model = nn.DataParallel(model)\n\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.192676Z","iopub.execute_input":"2024-11-13T04:36:11.192979Z","iopub.status.idle":"2024-11-13T04:36:11.199001Z","shell.execute_reply.started":"2024-11-13T04:36:11.192947Z","shell.execute_reply":"2024-11-13T04:36:11.198079Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Loss and Optimizer\ncriterion = nn.MSELoss()  # Mean Squared Error for reconstruction loss\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.200158Z","iopub.execute_input":"2024-11-13T04:36:11.200435Z","iopub.status.idle":"2024-11-13T04:36:11.205425Z","shell.execute_reply.started":"2024-11-13T04:36:11.200405Z","shell.execute_reply":"2024-11-13T04:36:11.204434Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Initialize GradScaler for mixed precision training\nscaler = GradScaler()\n\nnum_epochs = 300  # Adjust as needed\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for batch_idx, (batch_data,) in enumerate(data_loader):\n        batch_data = batch_data.to(device)\n        batch_data = batch_data.unsqueeze(1)  # Ensure correct shape\n\n        # Forward and backward pass under autocast for mixed precision\n        with autocast():\n            output = model(batch_data)\n            loss = criterion(output, batch_data)\n        \n        # Scale loss to prevent underflow and backpropagate\n        scaler.scale(loss).backward()\n        \n        # Optimizer step with scaled gradients\n        scaler.step(optimizer)\n        scaler.update()  # Update scaler for next iteration\n        optimizer.zero_grad()  # Reset gradients\n        \n        running_loss += loss.item()\n    \n    avg_loss = running_loss / len(data_loader)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T04:36:11.206972Z","iopub.execute_input":"2024-11-13T04:36:11.207574Z","iopub.status.idle":"2024-11-13T06:45:42.146657Z","shell.execute_reply.started":"2024-11-13T04:36:11.207526Z","shell.execute_reply":"2024-11-13T06:45:42.145652Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3145811936.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n/tmp/ipykernel_30/3145811936.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/300], Loss: 0.9786\nEpoch [2/300], Loss: 0.8998\nEpoch [3/300], Loss: 0.7578\nEpoch [4/300], Loss: 0.5766\nEpoch [5/300], Loss: 0.4203\nEpoch [6/300], Loss: 0.3072\nEpoch [7/300], Loss: 0.2293\nEpoch [8/300], Loss: 0.1735\nEpoch [9/300], Loss: 0.1344\nEpoch [10/300], Loss: 0.1073\nEpoch [11/300], Loss: 0.0885\nEpoch [12/300], Loss: 0.0756\nEpoch [13/300], Loss: 0.0658\nEpoch [14/300], Loss: 0.0579\nEpoch [15/300], Loss: 0.0515\nEpoch [16/300], Loss: 0.0460\nEpoch [17/300], Loss: 0.0412\nEpoch [18/300], Loss: 0.0371\nEpoch [19/300], Loss: 0.0336\nEpoch [20/300], Loss: 0.0303\nEpoch [21/300], Loss: 0.0275\nEpoch [22/300], Loss: 0.0251\nEpoch [23/300], Loss: 0.0229\nEpoch [24/300], Loss: 0.0210\nEpoch [25/300], Loss: 0.0193\nEpoch [26/300], Loss: 0.0178\nEpoch [27/300], Loss: 0.0164\nEpoch [28/300], Loss: 0.0152\nEpoch [29/300], Loss: 0.0141\nEpoch [30/300], Loss: 0.0131\nEpoch [31/300], Loss: 0.0122\nEpoch [32/300], Loss: 0.0114\nEpoch [33/300], Loss: 0.0107\nEpoch [34/300], Loss: 0.0100\nEpoch [35/300], Loss: 0.0094\nEpoch [36/300], Loss: 0.0089\nEpoch [37/300], Loss: 0.0084\nEpoch [38/300], Loss: 0.0080\nEpoch [39/300], Loss: 0.0076\nEpoch [40/300], Loss: 0.0072\nEpoch [41/300], Loss: 0.0069\nEpoch [42/300], Loss: 0.0065\nEpoch [43/300], Loss: 0.0063\nEpoch [44/300], Loss: 0.0060\nEpoch [45/300], Loss: 0.0058\nEpoch [46/300], Loss: 0.0056\nEpoch [47/300], Loss: 0.0054\nEpoch [48/300], Loss: 0.0052\nEpoch [49/300], Loss: 0.0050\nEpoch [50/300], Loss: 0.0048\nEpoch [51/300], Loss: 0.0047\nEpoch [52/300], Loss: 0.0046\nEpoch [53/300], Loss: 0.0044\nEpoch [54/300], Loss: 0.0043\nEpoch [55/300], Loss: 0.0042\nEpoch [56/300], Loss: 0.0041\nEpoch [57/300], Loss: 0.0040\nEpoch [58/300], Loss: 0.0039\nEpoch [59/300], Loss: 0.0038\nEpoch [60/300], Loss: 0.0037\nEpoch [61/300], Loss: 0.0036\nEpoch [62/300], Loss: 0.0036\nEpoch [63/300], Loss: 0.0035\nEpoch [64/300], Loss: 0.0034\nEpoch [65/300], Loss: 0.0033\nEpoch [66/300], Loss: 0.0033\nEpoch [67/300], Loss: 0.0032\nEpoch [68/300], Loss: 0.0031\nEpoch [69/300], Loss: 0.0031\nEpoch [70/300], Loss: 0.0030\nEpoch [71/300], Loss: 0.0030\nEpoch [72/300], Loss: 0.0029\nEpoch [73/300], Loss: 0.0029\nEpoch [74/300], Loss: 0.0028\nEpoch [75/300], Loss: 0.0028\nEpoch [76/300], Loss: 0.0027\nEpoch [77/300], Loss: 0.0027\nEpoch [78/300], Loss: 0.0026\nEpoch [79/300], Loss: 0.0026\nEpoch [80/300], Loss: 0.0025\nEpoch [81/300], Loss: 0.0025\nEpoch [82/300], Loss: 0.0025\nEpoch [83/300], Loss: 0.0024\nEpoch [84/300], Loss: 0.0024\nEpoch [85/300], Loss: 0.0023\nEpoch [86/300], Loss: 0.0023\nEpoch [87/300], Loss: 0.0023\nEpoch [88/300], Loss: 0.0022\nEpoch [89/300], Loss: 0.0022\nEpoch [90/300], Loss: 0.0022\nEpoch [91/300], Loss: 0.0021\nEpoch [92/300], Loss: 0.0021\nEpoch [93/300], Loss: 0.0021\nEpoch [94/300], Loss: 0.0021\nEpoch [95/300], Loss: 0.0020\nEpoch [96/300], Loss: 0.0020\nEpoch [97/300], Loss: 0.0020\nEpoch [98/300], Loss: 0.0020\nEpoch [99/300], Loss: 0.0019\nEpoch [100/300], Loss: 0.0019\nEpoch [101/300], Loss: 0.0019\nEpoch [102/300], Loss: 0.0019\nEpoch [103/300], Loss: 0.0018\nEpoch [104/300], Loss: 0.0018\nEpoch [105/300], Loss: 0.0018\nEpoch [106/300], Loss: 0.0018\nEpoch [107/300], Loss: 0.0017\nEpoch [108/300], Loss: 0.0017\nEpoch [109/300], Loss: 0.0017\nEpoch [110/300], Loss: 0.0017\nEpoch [111/300], Loss: 0.0017\nEpoch [112/300], Loss: 0.0016\nEpoch [113/300], Loss: 0.0016\nEpoch [114/300], Loss: 0.0016\nEpoch [115/300], Loss: 0.0016\nEpoch [116/300], Loss: 0.0016\nEpoch [117/300], Loss: 0.0015\nEpoch [118/300], Loss: 0.0015\nEpoch [119/300], Loss: 0.0015\nEpoch [120/300], Loss: 0.0015\nEpoch [121/300], Loss: 0.0015\nEpoch [122/300], Loss: 0.0015\nEpoch [123/300], Loss: 0.0014\nEpoch [124/300], Loss: 0.0014\nEpoch [125/300], Loss: 0.0014\nEpoch [126/300], Loss: 0.0014\nEpoch [127/300], Loss: 0.0014\nEpoch [128/300], Loss: 0.0013\nEpoch [129/300], Loss: 0.0013\nEpoch [130/300], Loss: 0.0013\nEpoch [131/300], Loss: 0.0013\nEpoch [132/300], Loss: 0.0013\nEpoch [133/300], Loss: 0.0013\nEpoch [134/300], Loss: 0.0012\nEpoch [135/300], Loss: 0.0012\nEpoch [136/300], Loss: 0.0012\nEpoch [137/300], Loss: 0.0012\nEpoch [138/300], Loss: 0.0012\nEpoch [139/300], Loss: 0.0012\nEpoch [140/300], Loss: 0.0012\nEpoch [141/300], Loss: 0.0011\nEpoch [142/300], Loss: 0.0011\nEpoch [143/300], Loss: 0.0011\nEpoch [144/300], Loss: 0.0011\nEpoch [145/300], Loss: 0.0011\nEpoch [146/300], Loss: 0.0011\nEpoch [147/300], Loss: 0.0011\nEpoch [148/300], Loss: 0.0010\nEpoch [149/300], Loss: 0.0011\nEpoch [150/300], Loss: 0.0010\nEpoch [151/300], Loss: 0.0010\nEpoch [152/300], Loss: 0.0010\nEpoch [153/300], Loss: 0.0010\nEpoch [154/300], Loss: 0.0010\nEpoch [155/300], Loss: 0.0010\nEpoch [156/300], Loss: 0.0010\nEpoch [157/300], Loss: 0.0010\nEpoch [158/300], Loss: 0.0009\nEpoch [159/300], Loss: 0.0009\nEpoch [160/300], Loss: 0.0009\nEpoch [161/300], Loss: 0.0009\nEpoch [162/300], Loss: 0.0009\nEpoch [163/300], Loss: 0.0009\nEpoch [164/300], Loss: 0.0009\nEpoch [165/300], Loss: 0.0009\nEpoch [166/300], Loss: 0.0009\nEpoch [167/300], Loss: 0.0008\nEpoch [168/300], Loss: 0.0008\nEpoch [169/300], Loss: 0.0008\nEpoch [170/300], Loss: 0.0008\nEpoch [171/300], Loss: 0.0008\nEpoch [172/300], Loss: 0.0008\nEpoch [173/300], Loss: 0.0008\nEpoch [174/300], Loss: 0.0008\nEpoch [175/300], Loss: 0.0008\nEpoch [176/300], Loss: 0.0008\nEpoch [177/300], Loss: 0.0008\nEpoch [178/300], Loss: 0.0008\nEpoch [179/300], Loss: 0.0007\nEpoch [180/300], Loss: 0.0007\nEpoch [181/300], Loss: 0.0007\nEpoch [182/300], Loss: 0.0007\nEpoch [183/300], Loss: 0.0007\nEpoch [184/300], Loss: 0.0007\nEpoch [185/300], Loss: 0.0007\nEpoch [186/300], Loss: 0.0007\nEpoch [187/300], Loss: 0.0007\nEpoch [188/300], Loss: 0.0007\nEpoch [189/300], Loss: 0.0007\nEpoch [190/300], Loss: 0.0007\nEpoch [191/300], Loss: 0.0007\nEpoch [192/300], Loss: 0.0007\nEpoch [193/300], Loss: 0.0006\nEpoch [194/300], Loss: 0.0006\nEpoch [195/300], Loss: 0.0006\nEpoch [196/300], Loss: 0.0007\nEpoch [197/300], Loss: 0.0006\nEpoch [198/300], Loss: 0.0006\nEpoch [199/300], Loss: 0.0006\nEpoch [200/300], Loss: 0.0006\nEpoch [201/300], Loss: 0.0006\nEpoch [202/300], Loss: 0.0006\nEpoch [203/300], Loss: 0.0006\nEpoch [204/300], Loss: 0.0006\nEpoch [205/300], Loss: 0.0006\nEpoch [206/300], Loss: 0.0006\nEpoch [207/300], Loss: 0.0006\nEpoch [208/300], Loss: 0.0006\nEpoch [209/300], Loss: 0.0006\nEpoch [210/300], Loss: 0.0005\nEpoch [211/300], Loss: 0.0006\nEpoch [212/300], Loss: 0.0005\nEpoch [213/300], Loss: 0.0005\nEpoch [214/300], Loss: 0.0005\nEpoch [215/300], Loss: 0.0005\nEpoch [216/300], Loss: 0.0005\nEpoch [217/300], Loss: 0.0005\nEpoch [218/300], Loss: 0.0005\nEpoch [219/300], Loss: 0.0005\nEpoch [220/300], Loss: 0.0005\nEpoch [221/300], Loss: 0.0005\nEpoch [222/300], Loss: 0.0005\nEpoch [223/300], Loss: 0.0005\nEpoch [224/300], Loss: 0.0005\nEpoch [225/300], Loss: 0.0005\nEpoch [226/300], Loss: 0.0005\nEpoch [227/300], Loss: 0.0005\nEpoch [228/300], Loss: 0.0005\nEpoch [229/300], Loss: 0.0005\nEpoch [230/300], Loss: 0.0005\nEpoch [231/300], Loss: 0.0005\nEpoch [232/300], Loss: 0.0004\nEpoch [233/300], Loss: 0.0005\nEpoch [234/300], Loss: 0.0004\nEpoch [235/300], Loss: 0.0004\nEpoch [236/300], Loss: 0.0004\nEpoch [237/300], Loss: 0.0004\nEpoch [238/300], Loss: 0.0005\nEpoch [239/300], Loss: 0.0004\nEpoch [240/300], Loss: 0.0004\nEpoch [241/300], Loss: 0.0004\nEpoch [242/300], Loss: 0.0004\nEpoch [243/300], Loss: 0.0004\nEpoch [244/300], Loss: 0.0004\nEpoch [245/300], Loss: 0.0004\nEpoch [246/300], Loss: 0.0004\nEpoch [247/300], Loss: 0.0004\nEpoch [248/300], Loss: 0.0004\nEpoch [249/300], Loss: 0.0004\nEpoch [250/300], Loss: 0.0004\nEpoch [251/300], Loss: 0.0004\nEpoch [252/300], Loss: 0.0004\nEpoch [253/300], Loss: 0.0004\nEpoch [254/300], Loss: 0.0004\nEpoch [255/300], Loss: 0.0004\nEpoch [256/300], Loss: 0.0004\nEpoch [257/300], Loss: 0.0004\nEpoch [258/300], Loss: 0.0004\nEpoch [259/300], Loss: 0.0004\nEpoch [260/300], Loss: 0.0004\nEpoch [261/300], Loss: 0.0004\nEpoch [262/300], Loss: 0.0003\nEpoch [263/300], Loss: 0.0003\nEpoch [264/300], Loss: 0.0004\nEpoch [265/300], Loss: 0.0003\nEpoch [266/300], Loss: 0.0003\nEpoch [267/300], Loss: 0.0003\nEpoch [268/300], Loss: 0.0003\nEpoch [269/300], Loss: 0.0003\nEpoch [270/300], Loss: 0.0003\nEpoch [271/300], Loss: 0.0003\nEpoch [272/300], Loss: 0.0003\nEpoch [273/300], Loss: 0.0003\nEpoch [274/300], Loss: 0.0003\nEpoch [275/300], Loss: 0.0003\nEpoch [276/300], Loss: 0.0003\nEpoch [277/300], Loss: 0.0003\nEpoch [278/300], Loss: 0.0003\nEpoch [279/300], Loss: 0.0003\nEpoch [280/300], Loss: 0.0003\nEpoch [281/300], Loss: 0.0003\nEpoch [282/300], Loss: 0.0003\nEpoch [283/300], Loss: 0.0003\nEpoch [284/300], Loss: 0.0003\nEpoch [285/300], Loss: 0.0003\nEpoch [286/300], Loss: 0.0003\nEpoch [287/300], Loss: 0.0003\nEpoch [288/300], Loss: 0.0003\nEpoch [289/300], Loss: 0.0003\nEpoch [290/300], Loss: 0.0003\nEpoch [291/300], Loss: 0.0003\nEpoch [292/300], Loss: 0.0003\nEpoch [293/300], Loss: 0.0003\nEpoch [294/300], Loss: 0.0003\nEpoch [295/300], Loss: 0.0003\nEpoch [296/300], Loss: 0.0003\nEpoch [297/300], Loss: 0.0003\nEpoch [298/300], Loss: 0.0003\nEpoch [299/300], Loss: 0.0003\nEpoch [300/300], Loss: 0.0003\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import numpy as np\nfrom torch.cuda.amp import autocast\n\nmodel.eval()\nreconstruction_errors = []\n\nwith torch.no_grad():\n    for batch_idx, (batch_data,) in enumerate(data_loader):\n        batch_data = batch_data.to(device)\n        batch_data = batch_data.unsqueeze(1)  \n\n        with autocast():\n            output = model(batch_data)\n\n        error = torch.mean((batch_data - output) ** 2, dim=[1, 2]).cpu().numpy()\n        reconstruction_errors.extend(error)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:45:42.147968Z","iopub.execute_input":"2024-11-13T06:45:42.148349Z","iopub.status.idle":"2024-11-13T06:46:08.596848Z","shell.execute_reply.started":"2024-11-13T06:45:42.148306Z","shell.execute_reply":"2024-11-13T06:46:08.595924Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2510274684.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"threshold = np.percentile(reconstruction_errors, 95)\n\nanomalies = np.array(reconstruction_errors) > threshold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:46:08.598022Z","iopub.execute_input":"2024-11-13T06:46:08.600247Z","iopub.status.idle":"2024-11-13T06:46:09.008119Z","shell.execute_reply.started":"2024-11-13T06:46:08.600208Z","shell.execute_reply":"2024-11-13T06:46:09.007181Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"total_anomalies = (anomalies==True).sum()\ntotal_anomalies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:49:13.403244Z","iopub.execute_input":"2024-11-13T06:49:13.403601Z","iopub.status.idle":"2024-11-13T06:49:13.411817Z","shell.execute_reply.started":"2024-11-13T06:49:13.403569Z","shell.execute_reply":"2024-11-13T06:49:13.410922Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"129600"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"(anomalies==False).sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:46:09.022722Z","iopub.execute_input":"2024-11-13T06:46:09.023053Z","iopub.status.idle":"2024-11-13T06:46:09.031208Z","shell.execute_reply.started":"2024-11-13T06:46:09.023020Z","shell.execute_reply":"2024-11-13T06:46:09.030266Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"2462400"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"df[\"Anomaly\"] = anomalies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:46:09.032233Z","iopub.execute_input":"2024-11-13T06:46:09.032506Z","iopub.status.idle":"2024-11-13T06:46:09.037853Z","shell.execute_reply.started":"2024-11-13T06:46:09.032477Z","shell.execute_reply":"2024-11-13T06:46:09.036913Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"df.to_csv(\"/kaggle/working/house_a_detected_anomalies.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:46:09.039056Z","iopub.execute_input":"2024-11-13T06:46:09.039458Z","iopub.status.idle":"2024-11-13T06:46:30.905915Z","shell.execute_reply.started":"2024-11-13T06:46:09.039408Z","shell.execute_reply":"2024-11-13T06:46:30.905156Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:47:55.591139Z","iopub.execute_input":"2024-11-13T06:47:55.591508Z","iopub.status.idle":"2024-11-13T06:47:55.598191Z","shell.execute_reply.started":"2024-11-13T06:47:55.591477Z","shell.execute_reply":"2024-11-13T06:47:55.597008Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"2592000"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"print(f\"Percentage Anomalies = {(total_anomalies/len(df))*100}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T06:49:19.530784Z","iopub.execute_input":"2024-11-13T06:49:19.531647Z","iopub.status.idle":"2024-11-13T06:49:19.536452Z","shell.execute_reply.started":"2024-11-13T06:49:19.531605Z","shell.execute_reply":"2024-11-13T06:49:19.535439Z"}},"outputs":[{"name":"stdout","text":"Percentage Anomalies = 5.0%\n","output_type":"stream"}],"execution_count":34}]}