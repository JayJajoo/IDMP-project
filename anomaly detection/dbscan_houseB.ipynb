{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DAY_1.txt', 'DAY_2.txt', 'DAY_3.txt', 'DAY_4.txt', 'DAY_5.txt', 'DAY_6.txt', 'DAY_7.txt', 'DAY_8.txt', 'DAY_9.txt', 'DAY_10.txt', 'DAY_11.txt', 'DAY_12.txt', 'DAY_13.txt', 'DAY_14.txt', 'DAY_15.txt', 'DAY_16.txt', 'DAY_17.txt', 'DAY_18.txt', 'DAY_19.txt', 'DAY_20.txt', 'DAY_21.txt', 'DAY_22.txt', 'DAY_23.txt', 'DAY_24.txt', 'DAY_25.txt', 'DAY_26.txt', 'DAY_27.txt', 'DAY_28.txt', 'DAY_29.txt', 'DAY_30.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_path = \"../Aras/House B\"\n",
    "txt_files = os.listdir(base_path)[:-1]\n",
    "\n",
    "sorted_txt_files = sorted(txt_files, key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "print(sorted_txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAY_1.txt done.  (86400, 23)\n",
      "DAY_2.txt done.  (172800, 23)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m sensor_data_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(sensor_data_scaled)\n\u001b[0;32m     13\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mdbscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensor_data_pca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m dbscan\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m     16\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDBSCAN_Labels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labels\n",
      "File \u001b[1;32md:\\anaconda\\envs\\PT\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\PT\\Lib\\site-packages\\sklearn\\cluster\\_dbscan.py:436\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# A list of all core samples found.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m core_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_neighbors \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m--> 436\u001b[0m \u001b[43mdbscan_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighborhoods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore_sample_indices_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(core_samples)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_ \u001b[38;5;241m=\u001b[39m labels\n",
      "File \u001b[1;32m_dbscan_inner.pyx:33\u001b[0m, in \u001b[0;36msklearn.cluster._dbscan_inner.dbscan_inner\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "\n",
    "for txt in sorted_txt_files:\n",
    "    data = pd.read_csv(f\"{base_path}/{txt}\",sep=' ', header=None)\n",
    "    sensor_data = data.iloc[:, :-2].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    sensor_data_scaled = scaler.fit_transform(sensor_data)\n",
    "    \n",
    "    pca = PCA(n_components=5) \n",
    "    sensor_data_pca = pca.fit_transform(sensor_data_scaled)\n",
    "\n",
    "    dbscan = DBSCAN(eps=0.4, min_samples=4)\n",
    "    dbscan.fit(sensor_data_pca)\n",
    "    labels = dbscan.labels_\n",
    "    data['DBSCAN_Labels'] = labels\n",
    "    final_df = pd.concat([final_df,data])\n",
    "    print(f\"{txt} done.\",f\" {final_df.shape}\")\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4725"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_df[\"DBSCAN_Labels\"]==-1).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
